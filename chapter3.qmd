# Dataframes and Series 

## Data types

Polars allows you to store data in a variety of formats called data types. These data types fall generally into the following categories:

- **Numeric**: Signed integers, unsigned integers, floating point numbers, and decimals
- **Nested**: Lists, structs, and arrays for handling complex data
- **Temporal**: Dates, datetimes, and times for working with time-based data
- **Miscellaneous**: Strings, binary data, Booleans, categoricals, enums, and objects

The most common data types you will be working with are generally: Strings, signed and unsigned integers, floating point numbers or floats, decimals, dates or datetimes and booleans. For more information on each of these data types see @sec-appendix-a.

## Series

The two most common data structures in Polars are DataFrames and Series. Series are one-dimensional data structures where

Creating a Series is straightforward with the following syntax:

`pl.Series(name, values_list)`

Where "name" is the label for your Series and "values_list" contains the data. Here's a simple example:
```{python}
import polars as pl
s = pl.Series("example", [1, 2, 3, 4, 5])
s
```

When you create a series Polars will infer the data type for the values you provide. So in the above example I gave it [1, 2, 3, 4, 5] and it set the datatype to Int64 if instead gave it [1, 2, 3, 4.0, 5] it would asume it is Float64.


```{python}
s2 = pl.Series("payment", [132.50, 120, 116, 98.75 ,42])
s2
```

```{python}
s3 = pl.Series("mixed", [1, "text", True, 3.14], strict=False)
# series.dytpe outputs a the data type of the series
print(f"Mixed series type: {s3.dtype}")
s3
```

You can set the data type of the series as well by using the `dtype` parameter. A example use case is when storing a id number the id number should be stored as a string not a int due to the fact that we we do not want to perform mathmatical operations on the identification number therefore it is best stored as a string.


```{python}
# strict=False allows automatic conversion from different data types
s3 = pl.Series("id number", [143823, 194203, 553420, 234325, 236532], dtype=pl.Utf8, strict=False)
s3
```

## Dataframes

DataFrames are tabular data structures (rows and columns) composed of multiple Series, with each column representing a single Series. The design of a dataframe is called schema. A schema is a mapping of column to the data types. 

Dataframes are the workhorses of data analysis and what you’ll use most frequently.

With DataFrames, you can write powerful queries to filter, transform, aggregate, and reshape your data efficiently.

DataFrames can be created in several ways:

1. From a dictionary of sequences (lists, arrays)
2. With explicit schema specification 
3. From a sequence of (name, dtype) pairs
4. From NumPy arrays
5. From a list of lists (row-oriented data)
6. By converting pandas DataFrames
7. By importing existing tabular data from CSVs, JSON, SQL, Parquet files, etc.

In real-world environments, you’ll typically work with preexisting data, though understanding various creation methods is valuable. We’ll cover data import techniques later, but for now, here’s an example of a DataFrame created from a dictionary of lists:
```{python}
# Create a DataFrame from a dictionary of lists
df = pl.DataFrame({
    "name": ["Alice", "Bob", "Charlie", "David"],
    "age": [25, 30, 35, 40],
    "city": ["New York", "Boston", "Chicago", "Seattle"],
    "salary": [75000, 85000, 90000, 95000]
})

df
```

every data frame has a shape. the shape is the number of rows and columns in a dataframe 
`shape(rows,columns)`

the shape for the above dataframe is:

```{python}
print(df.shape)
```

you can view the schema of any dataframe with the following command 

```{python}
print(df.schema)
```

We see here that the schema is returned as a dictionary. In the above example the column name has the string datatype. Though you can view the data type already when displaying the dataframe.

## Inspecting Dataframes

In polars there are a varity of ways to inspect a dataframe, all of which have different use cases. The ones that we will be covering right now are:

- head 
- tail 
- glimpse
- sample
- describe
- slice

### head 

the `head` functions allows you to view the first x rows of the dataframe. By default the number of rows it shows is 5, though you can specify the number of rows to view.

```python
dataframe.head(n)
```
Where n is the number of rows to return if you give it a negative number it will turn all rows except the last n rows.

```{python}
import numpy as np

# Create NumPy arrays for sandwich data
sandwich_names = np.array(['BLT', 'Club', 'Tuna', 'Ham & Cheese', 'Veggie'])
prices = np.array([8.99, 10.50, 7.50, 6.99, 6.50])
calories = np.array([550, 720, 480, 520, 320])
vegetarian = np.array([False, False, False, False, True])

# Create DataFrame from NumPy arrays
sandwich_df = pl.DataFrame({
    "sandwich": sandwich_names,
    "price": prices,
    "calories": calories,
    "vegetarian": vegetarian
})


sandwich_df.head(3)
```

### tail

The `tail` function is essentially the inverse of head. It allows you to view the last n rows of the dataframe. The default for tail is also five rows.

```python
dataframe.tail(n)
```
Where n is the number of rows to return if you give it a negative number it will turn all rows except the first n rows.


```{python}
# Import data from the sales.csv file into a Polars DataFrame
sales_df = pl.read_csv("./data/sales.csv")

# Display the last 6 rows of the sales DataFrame
sales_df.tail(6)
```

::: {.callout-note}
For more information on reading in external data see @sec-appendix-b
:::