# Reading and Writing Data {#sec-appendix-b}

Polars provides robust capabilities for importing data from various sources including CSVs, JSONs, Excel spreadsheets, Parquet files, cloud storage solutions (AWS, Azure, and Google Cloud), and databases.

The importing methods follow a consistent pattern across file types, making it easy to work with different data formats.

## CSV Files

The basic syntax for reading a CSV file is:
```python
pl.read_csv("path/to/data.csv")
```

Alternatively, you can also read CSV files directly from the internet:
```python
pl.read_csv("https://example.com/path/to/your/file.csv")
```
This capability to read files directly from URLs also works with all the file import methods we'll cover below.


This function offers numerous parameters to handle different CSV formats and configurations. For more information read the [documentation](https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.read_csv.html).

```{python}
import polars as pl

df_csv = pl.read_csv("./data/example.csv", try_parse_dates=True)
df_csv.head(5)
```



## JSON Files

Reading JSON files follows a similar pattern. The basic syntax is:
```python
pl.read_json("docs/data/path.json")
```

JSON files have a more standardized structure than CSVs, so the reading process requires fewer configuration parameters. Polars handles JSON parsing efficiently with minimal setup. For advanced options and configurations, consult the official [documentation](https://docs.pola.rs/api/python/stable/reference/api/polars.read_json.html).

```python
df_json = pl.read_json("./data/basketball.json")

df_json
```

## Excel 

Polars doesn't include a native Excel reader. Instead, it leverages external libraries like fastexcel, xlsx2csv, or openpyxl to parse Excel files into Polars-compatible formats. Among these options, Polars recommends fastexcel for optimal performance. 

While it's generally better to avoid using Excel files where possible (you can usually export as CSV directly from Excel), reading Excel files is straightforward with the right dependencies installed.

Before attempting to read Excel files, make sure you have at least one of these libraries installed:
```bash
 $ pip install fastexcel xlsx2csv openpyxl
 ```


The basic syntax for reading an Excel file with Polars is:
```python
pl.read_excel("path/to/data.xlsx")
```

If your Excel file contains multiple sheets, you can specify which one to read using the `sheet_name` parameter:
```python
df = pl.read_excel("path/to/data.xlsx", sheet_name="example")
```

For additional Excel reading options and parameters, refer to the [Polars Excel documentation](https://docs.pola.rs/api/python/stable/reference/api/polars.read_excel.html), which covers sheet selection, range specification, and handling of complex Excel files.

```{python}
df_xlsx = pl.read_excel("./data/penguins.xlsx", sheet_name="Dream Island")

df_xlsx.tail(5)
```

This example spreadsheet can be accessed via [this Google Sheets link](https://docs.google.com/spreadsheets/d/1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY/edit?gid=0#gid=0).

## Parquet Files

Parquet is a columnar storage format designed for efficient data analytics. It provides excellent compression and fast query performance, making it a popular choice for data science workflows. Polars includes native, high-performance support for reading Parquet files.

The basic syntax for reading a Parquet file is:

```python
pl.read_parquet("path/to/data.parquet")
```

```{python}
df_par = pl.read_parquet("./data/finance.parquet")
df_par.sample(4)
```

## Importing Mutiple files

For situations where you need to combine data from multiple files into a single DataFrame, Polars offers straightforward approaches. While the syntax is relatively simple, the implementation may vary depending on your specific file organization.

When working with multiple files of the same type and similar naming patterns in a single directory, Polars supports glob pattern matching:

```python
pl.read_filetype("path/to/data/my_many_files_*.filetype")
```
For files with different names but the same format, placing them in a single directory allows you to use wildcard patterns to import them all at once:

```python
pl.read_filetype("path/to/data/import/*.filetype")
```
Alternatively, for files located in different directories or even on different servers, you can provide a list of filepaths or URLs:

```python
pl.read_filetype([
    "path/to/first/file.filetype",
    "path/to/second/file.filetype",
    "another/location/file.filetype"
])
```
If you're working with different file types that share the same schema (identical columns and datatypes) and want to combine them into a single DataFrame, you'll need to read each file individually and then concatenate them. Polars makes this process straightforward with its `concat` function, which can merge DataFrames regardless of their original file formats.

```python
# Read files of different formats
df1 = pl.read_csv("path/to/file.csv")
df2 = pl.read_parquet("path/to/file.parquet")
df3 = pl.read_json("path/to/file.json")

# Concatenate into a single DataFrame
combined_df = pl.concat([df1, df2, df3], how="vertical")
```